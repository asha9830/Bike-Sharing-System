{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e6f0121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b92e3cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession.Builder object at 0x0000022E78B171C0>\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.config(\"spark.driver.host\", \"localhost\")\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6c3d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spark = SparkSession.builder.appName('DataFrame1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3050c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_df = data_spark.read.option('header','true').csv('Bike Sharing/day.csv', inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22ccc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----+-------+-------+----------+----------+---------+--------+-------+---------+------+----+\n",
      "|season| yr|mnth|holiday|weekday|workingday|weathersit|     temp|   atemp|    hum|windspeed|casual| cnt|\n",
      "+------+---+----+-------+-------+----------+----------+---------+--------+-------+---------+------+----+\n",
      "|     1|  0|   1|      0|      6|         0|         2|14.110847|18.18125|80.5833|10.749882|   331| 985|\n",
      "|     1|  0|   1|      0|      0|         0|         2|14.902598|17.68695|69.6087|16.652113|   131| 801|\n",
      "|     1|  0|   1|      0|      1|         1|         1| 8.050924| 9.47025|43.7273|16.636703|   120|1349|\n",
      "|     1|  0|   1|      0|      2|         1|         1|      8.2| 10.6061|59.0435|10.739832|   108|1562|\n",
      "|     1|  0|   1|      0|      3|         1|         1| 9.305237| 11.4635|43.6957|  12.5223|    82|1600|\n",
      "|     1|  0|   1|      0|      4|         1|         1| 8.378268|11.66045|51.8261|6.0008684|    88|1606|\n",
      "|     1|  0|   1|      0|      5|         1|         2| 8.057402|10.44195|49.8696|11.304642|   148|1510|\n",
      "|     1|  0|   1|      0|      6|         0|         2|    6.765|  8.1127|53.5833|17.875868|    68| 959|\n",
      "|     1|  0|   1|      0|      0|         0|         1| 5.671653| 5.80875|43.4167| 24.25065|    54| 822|\n",
      "|     1|  0|   1|      0|      1|         1|         1| 6.184153|  7.5444|48.2917|14.958889|    41|1321|\n",
      "|     1|  0|   1|      0|      2|         1|         2| 6.932731|  9.5732|68.6364| 8.182844|    43|1263|\n",
      "|     1|  0|   1|      0|      3|         1|         1| 7.081807| 8.02365|59.9545|20.410009|    25|1162|\n",
      "|     1|  0|   1|      0|      4|         1|         1|    6.765| 7.54415|47.0417|   20.167|    38|1406|\n",
      "|     1|  0|   1|      0|      5|         1|         1|  6.59567| 9.42065|53.7826| 8.478716|    54|1421|\n",
      "|     1|  0|   1|      0|      6|         0|         2| 9.566653| 12.4056| 49.875|10.583521|   222|1248|\n",
      "|     1|  0|   1|      0|      0|         0|         1| 9.498347|11.71085| 48.375|12.625011|   251|1204|\n",
      "|     1|  0|   1|      1|      1|         0|         2| 7.209153| 8.83855|  53.75|12.999139|   117|1000|\n",
      "|     1|  0|   1|      0|      2|         1|         2| 8.883347|11.61665|86.1667| 9.833925|     9| 683|\n",
      "|     1|  0|   1|      0|      3|         1|         2|11.979134| 14.9211|74.1739|13.957239|    78|1650|\n",
      "|     1|  0|   1|      0|      4|         1|         2|10.728347| 12.7525|53.8333|13.125568|    83|1927|\n",
      "+------+---+----+-------+-------+----------+----------+---------+--------+-------+---------+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Droping Column Instant\n",
    "New_data = Spark_df.drop('instant','dteday','registered')\n",
    "New_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c739c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76169aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------------+--------------------+------------------+-------------------+------------------+-----------------+-----------------+------------------+------------------+-----------------+------------------+\n",
      "|summary|            season|                yr|             mnth|             holiday|           weekday|         workingday|        weathersit|             temp|            atemp|               hum|         windspeed|           casual|               cnt|\n",
      "+-------+------------------+------------------+-----------------+--------------------+------------------+-------------------+------------------+-----------------+-----------------+------------------+------------------+-----------------+------------------+\n",
      "|  count|               730|               730|              730|                 730|               730|                730|               730|              730|              730|               730|               730|              730|               730|\n",
      "|   mean|2.4986301369863013|               0.5|6.526027397260274|0.028767123287671233|2.9972602739726026| 0.6835616438356165|1.3945205479452054|20.31925921698629|23.72632162328766| 62.76517493150685|12.763619654657532|849.2493150684932| 4508.006849315068|\n",
      "| stddev|1.1101839527605597|0.5003428180039369| 3.45021529306815| 0.16726596126617505| 2.006161469480848|0.46540502549780344|0.5448072389026616|7.506728936951138| 8.15030776221679|14.237589043405647|  5.19584070408046|686.4798745344391|1936.0116473612586|\n",
      "|    min|                 1|                 0|                1|                   0|                 0|                  0|                 1|        2.4243464|          3.95348|               0.0|         1.5002439|                2|                22|\n",
      "|    max|                 4|                 1|               12|                   1|                 6|                  1|                 3|        35.328347|          42.0448|             97.25|         34.000021|             3410|              8714|\n",
      "+-------+------------------+------------------+-----------------+--------------------+------------------+-------------------+------------------+-----------------+-----------------+------------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "New_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1698300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'casual']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [item[0] for item in New_data.dtypes if item[1].startswith('string')]\n",
    "print(categorical_cols)\n",
    "\n",
    "numerical_cols = [item[0] for item in New_data.dtypes if item[1].startswith('int') | item[1].startswith('double')][:-1]\n",
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b56ba9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd504a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aede464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1230593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'casual']\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = [item[0] for item in New_data.dtypes if item[1].startswith('int') | item[1].startswith('double')][:-1]\n",
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37520707",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = []\n",
    "Vectassembler = VectorAssembler(inputCols=numerical_cols, outputCol=\"features\")\n",
    "stages += [Vectassembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3397d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = New_data.columns\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(New_data)\n",
    "New_data = pipelineModel.transform(New_data)\n",
    "selectedCols = ['features']+cols\n",
    "New_data = New_data.select(selectedCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88144fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "New_data = New_data.select(selectedCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5923f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(New_data.take(5), columns=New_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f7644b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features| cnt|\n",
      "+--------------------+----+\n",
      "|[1.0,0.0,1.0,0.0,...| 985|\n",
      "|[1.0,0.0,1.0,0.0,...| 801|\n",
      "|[1.0,0.0,1.0,0.0,...|1349|\n",
      "|[1.0,0.0,1.0,0.0,...|1562|\n",
      "|[1.0,0.0,1.0,0.0,...|1600|\n",
      "|[1.0,0.0,1.0,0.0,...|1606|\n",
      "|[1.0,0.0,1.0,0.0,...|1510|\n",
      "|[1.0,0.0,1.0,0.0,...| 959|\n",
      "|[1.0,0.0,1.0,0.0,...| 822|\n",
      "|[1.0,0.0,1.0,0.0,...|1321|\n",
      "|[1.0,0.0,1.0,0.0,...|1263|\n",
      "|[1.0,0.0,1.0,0.0,...|1162|\n",
      "|[1.0,0.0,1.0,0.0,...|1406|\n",
      "|[1.0,0.0,1.0,0.0,...|1421|\n",
      "|[1.0,0.0,1.0,0.0,...|1248|\n",
      "|[1.0,0.0,1.0,0.0,...|1204|\n",
      "|[1.0,0.0,1.0,1.0,...|1000|\n",
      "|[1.0,0.0,1.0,0.0,...| 683|\n",
      "|[1.0,0.0,1.0,0.0,...|1650|\n",
      "|[1.0,0.0,1.0,0.0,...|1927|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data = New_data.select(\"features\",\"cnt\")\n",
    "\n",
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1435b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and test model with 70% obs. going in training and 30% in testing\n",
    "train_dataset, test_dataset = finalized_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ddc6e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packeages for model creation\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.regression import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2523dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Multiple Linear Regression object named MLR having feature column as features and Label column as Profit\n",
    "Multiple_linear_Reg = LinearRegression(featuresCol=\"features\", labelCol=\"cnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7ac7f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model on the training using fit() method.\n",
    "model1 = Multiple_linear_Reg.fit(train_dataset)\n",
    "#Predict the Profit on Test Dataset using the evulate method\n",
    "Mult_pred = model1.evaluate(test_dataset)\n",
    "#Show the predicted Grade values along sid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8958e6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07824e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-------------------+\n",
      "|            features| cnt|         prediction|\n",
      "+--------------------+----+-------------------+\n",
      "|[1.0,0.0,1.0,0.0,...| 822|0.21016579982364192|\n",
      "|[1.0,0.0,1.0,0.0,...|1204|  906.7998125815807|\n",
      "|[1.0,0.0,1.0,0.0,...|1416| 1815.9758433187585|\n",
      "|[1.0,0.0,1.0,0.0,...|1562|  2078.869183642138|\n",
      "|[1.0,0.0,1.0,0.0,...|1600|  2138.232584634568|\n",
      "|[1.0,0.0,1.0,0.0,...| 506|  669.3328260679061|\n",
      "|[1.0,0.0,1.0,0.0,...|1606|  2351.667100972833|\n",
      "|[1.0,0.0,1.0,0.0,...| 981|  553.6135761441137|\n",
      "|[1.0,0.0,1.0,0.0,...| 959| 30.776996820588067|\n",
      "|[1.0,0.0,1.0,0.0,...|1248|  715.6067761540442|\n",
      "|[1.0,0.0,1.0,0.0,...| 985|  1059.314721160033|\n",
      "|[1.0,0.0,2.0,0.0,...|1812| 1564.1215901673536|\n",
      "|[1.0,0.0,2.0,0.0,...|1589| 1279.0162006087014|\n",
      "|[1.0,0.0,2.0,0.0,...|2402|  1895.535959585269|\n",
      "|[1.0,0.0,2.0,0.0,...|1712|  2434.925731453196|\n",
      "|[1.0,0.0,2.0,0.0,...|1360| 1669.3715216105604|\n",
      "|[1.0,0.0,2.0,0.0,...|2115| 2472.3837151729845|\n",
      "|[1.0,0.0,2.0,0.0,...|1605| 1360.8844799396395|\n",
      "|[1.0,0.0,2.0,0.0,...|1538| 1838.1385815514268|\n",
      "|[1.0,0.0,2.0,0.0,...|1746| 2378.2029246892776|\n",
      "+--------------------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Show the predicted Grade values along side actual Grade values\n",
    "Mult_pred.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3f71d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients of the model are : DenseVector([400.4065, 1528.7118, -16.6899, -237.531, 36.1624, 1369.2868, -464.9519, -50.308, 96.7123, -4.8321, -21.7367, 1.5206])\n"
     ]
    }
   ],
   "source": [
    "#Find out coefficient value\n",
    "coefficient = model1.coefficients\n",
    "print (\"The coefficients of the model are : %a\" %coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cc8ec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intercept of the model is : 459.808928\n"
     ]
    }
   ],
   "source": [
    "#Find out intercept Value\n",
    "intercept = model1.intercept\n",
    "print (\"The Intercept of the model is : %f\" %intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9002cd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.903\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model using metric like Mean Absolute Error(MAE), Root Mean Square Error(RMSE) and R-Square\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluation = RegressionEvaluator(labelCol=\"cnt\", predictionCol=\"prediction\")\n",
    "\n",
    "# r2 - coefficient of determination\n",
    "r2 = evaluation.evaluate(Mult_pred.predictions, {evaluation.metricName: \"r2\"})\n",
    "print(\"r2: %.3f\" %r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48b4b817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = model1.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25248c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 649.488215\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2031524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Unlabeled dataset  to contain only feature column\n",
    "unlabeled_dataset = test_dataset.select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bb962b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the model output for fresh & unseen test data using transform() method\n",
    "new_predictions = model1.transform(unlabeled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a75ce7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the new prediction values\n",
    "#new_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d13a1b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9868342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model on the training using fit() method.\n",
    "model1 = Multiple_linear_Reg.fit(train_dataset)\n",
    "#Predict the Profit on Test Dataset using the evulate method\n",
    "Mult_pred = model1.evaluate(test_dataset)\n",
    "#Show the predicted Grade values along sid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98016342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial Decision Tree Model\n",
    "decision_tree = DecisionTreeRegressor(labelCol=\"cnt\").fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4fd847f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_prediction = decision_tree.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "968e42e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+------------------+\n",
      "|            features| cnt|        prediction|\n",
      "+--------------------+----+------------------+\n",
      "|[1.0,0.0,1.0,0.0,...| 822|            1413.0|\n",
      "|[1.0,0.0,1.0,0.0,...|1204|2481.1428571428573|\n",
      "|[1.0,0.0,1.0,0.0,...|1416|2250.2820512820513|\n",
      "|[1.0,0.0,1.0,0.0,...|1562|2250.2820512820513|\n",
      "|[1.0,0.0,1.0,0.0,...|1600|2250.2820512820513|\n",
      "|[1.0,0.0,1.0,0.0,...| 506|             886.0|\n",
      "|[1.0,0.0,1.0,0.0,...|1606|2250.2820512820513|\n",
      "|[1.0,0.0,1.0,0.0,...| 981|1066.6666666666667|\n",
      "|[1.0,0.0,1.0,0.0,...| 959|1066.6666666666667|\n",
      "|[1.0,0.0,1.0,0.0,...|1248|          1844.375|\n",
      "|[1.0,0.0,1.0,0.0,...| 985|          1844.375|\n",
      "|[1.0,0.0,2.0,0.0,...|1812|2481.1428571428573|\n",
      "|[1.0,0.0,2.0,0.0,...|1589|2481.1428571428573|\n",
      "|[1.0,0.0,2.0,0.0,...|2402|          1844.375|\n",
      "|[1.0,0.0,2.0,0.0,...|1712|2250.2820512820513|\n",
      "|[1.0,0.0,2.0,0.0,...|1360|             886.0|\n",
      "|[1.0,0.0,2.0,0.0,...|2115|2262.6428571428573|\n",
      "|[1.0,0.0,2.0,0.0,...|1605|            1413.0|\n",
      "|[1.0,0.0,2.0,0.0,...|1538|            1413.0|\n",
      "|[1.0,0.0,2.0,0.0,...|1746|2250.2820512820513|\n",
      "+--------------------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree_prediction.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801cee8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6632e3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 891.329\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "decision_tree_evaluator = RegressionEvaluator(labelCol=\"cnt\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "decision_tree_rmse = decision_tree_evaluator.evaluate(decision_tree_prediction)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % decision_tree_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a4c8748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.797\n"
     ]
    }
   ],
   "source": [
    "# r2 - coefficient of determination\n",
    "dec_tree_r2 = evaluation.evaluate(decision_tree_prediction, {evaluation.metricName: \"r2\"})\n",
    "print(\"r2: %.3f\" %dec_tree_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ee14608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import allclose\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d194ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "random_forest = RandomForestRegressor(labelCol=\"cnt\").fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc4b8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_prediction = random_forest.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7106bde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+------------------+\n",
      "|            features| cnt|        prediction|\n",
      "+--------------------+----+------------------+\n",
      "|[1.0,0.0,1.0,0.0,...| 822|1302.2716658682887|\n",
      "|[1.0,0.0,1.0,0.0,...|1204|1969.2715843202036|\n",
      "|[1.0,0.0,1.0,0.0,...|1416|1627.7546990482274|\n",
      "|[1.0,0.0,1.0,0.0,...|1562|1604.1364326037185|\n",
      "|[1.0,0.0,1.0,0.0,...|1600|1675.4307307942588|\n",
      "|[1.0,0.0,1.0,0.0,...| 506|1064.2685723696593|\n",
      "|[1.0,0.0,1.0,0.0,...|1606|1583.8761642496925|\n",
      "|[1.0,0.0,1.0,0.0,...| 981|   1588.4701648496|\n",
      "|[1.0,0.0,1.0,0.0,...| 959|1366.8680108774458|\n",
      "|[1.0,0.0,1.0,0.0,...|1248|2041.1861142347334|\n",
      "|[1.0,0.0,1.0,0.0,...| 985|  2149.30192941908|\n",
      "|[1.0,0.0,2.0,0.0,...|1812| 2187.761227175467|\n",
      "|[1.0,0.0,2.0,0.0,...|1589|2105.2967512789833|\n",
      "|[1.0,0.0,2.0,0.0,...|2402|2384.9558074389374|\n",
      "|[1.0,0.0,2.0,0.0,...|1712| 1850.939187419987|\n",
      "|[1.0,0.0,2.0,0.0,...|1360|1318.2843132442044|\n",
      "|[1.0,0.0,2.0,0.0,...|2115| 2097.575911397372|\n",
      "|[1.0,0.0,2.0,0.0,...|1605|1471.0241330870601|\n",
      "|[1.0,0.0,2.0,0.0,...|1538|1458.8294902299172|\n",
      "|[1.0,0.0,2.0,0.0,...|1746|1788.2575028061096|\n",
      "+--------------------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_prediction.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "910a212c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 662.393\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "random_forest_evaluator = RegressionEvaluator(labelCol=\"cnt\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "random_forest_rmse = random_forest_evaluator.evaluate(random_forest_prediction)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % random_forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "904e1bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.888\n"
     ]
    }
   ],
   "source": [
    "# r2 - coefficient of determination\n",
    "rand_forest_r2 = evaluation.evaluate(random_forest_prediction, {evaluation.metricName: \"r2\"})\n",
    "print(\"r2: %.3f\" %rand_forest_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd460f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
